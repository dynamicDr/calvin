"""
ç»Ÿä¸€çš„ VLA æ¨¡åž‹æŽ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡åž‹
"""
import numpy as np
from calvin_agent.models.calvin_base_model import CalvinBaseModel
from typing import Literal


class MyVLAModel(CalvinBaseModel):
    def __init__(self,
                 model_type: Literal["random", "openvla", "rt2", "octo", "qwen2vl"] = "openvla",
                 model_path: str = None,
                 device: str = "cuda"):
        """
        åˆå§‹åŒ–VLAæ¨¡åž‹

        Args:
            model_type: æ¨¡åž‹ç±»åž‹ ("random", "openvla", "rt2", "octo", "qwen2vl")
            model_path: æ¨¡åž‹è·¯å¾„æˆ–HuggingFaceæ¨¡åž‹ID
            device: è¿è¡Œè®¾å¤‡
        """
        self.model_type = model_type
        self.device = device

        print(f"ðŸš€ åŠ è½½ {model_type.upper()} æ¨¡åž‹...")

        if model_type == "random":
            self._init_random()
        elif model_type == "openvla":
            self._init_openvla(model_path or "openvla/openvla-7b")
        elif model_type == "rt2":
            self._init_rt2(model_path or "google/rt-2-base")
        elif model_type == "octo":
            self._init_octo(model_path or "octo-base")
        elif model_type == "qwen2vl":
            self._init_qwen2vl(model_path or "Qwen/Qwen2-VL-8B-Instruct")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡åž‹ç±»åž‹: {model_type}")

        print(f"âœ… {model_type.upper()} æ¨¡åž‹åŠ è½½å®Œæˆ")

    def _init_random(self):
        """åˆå§‹åŒ–éšæœºåŠ¨ä½œæ¨¡åž‹ï¼ˆåŸºçº¿ï¼‰"""
        self.model = None
        self.action_bounds = {
            'xyz': (-0.02, 0.02),      # ä½ç½®å¢žé‡
            'rpy': (-0.05, 0.05),      # æ—‹è½¬å¢žé‡
            'gripper': [-1, 1]         # å¤¹çˆªå¼€åˆ
        }
        print("  ä½¿ç”¨éšæœºåŠ¨ä½œä½œä¸ºåŸºçº¿æ¨¡åž‹")

    def _init_openvla(self, model_path: str):
        """åˆå§‹åŒ– OpenVLA æ¨¡åž‹"""
        from transformers import AutoModelForVision2Seq, AutoProcessor
        import torch

        self.processor = AutoProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        self.model = AutoModelForVision2Seq.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            trust_remote_code=True
        ).to(self.device)
        self.model.eval()

    def _init_rt2(self, model_path: str):
        """åˆå§‹åŒ– RT-2 æ¨¡åž‹"""
        from transformers import RT2ForConditionalGeneration, AutoProcessor
        import torch

        self.processor = AutoProcessor.from_pretrained(model_path)
        self.model = RT2ForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16
        ).to(self.device)
        self.model.eval()

    def _init_octo(self, model_path: str):
        """åˆå§‹åŒ– Octo æ¨¡åž‹"""
        try:
            from octo.model.octo_model import OctoModel
            import jax

            self.model = OctoModel.load_pretrained(model_path)
            print(f"  ä½¿ç”¨è®¾å¤‡: {jax.devices()}")
        except ImportError:
            raise ImportError(
                "è¯·å®‰è£… Octo: pip install octo-models"
            )

    def _init_qwen2vl(self, model_path: str):
        """åˆå§‹åŒ– Qwen2-VL æ¨¡åž‹ï¼ˆéœ€è¦å¾®è°ƒé€‚é…åŠ¨ä½œè¾“å‡ºï¼‰"""
        from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
        import torch

        self.processor = AutoProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        self.model = Qwen2VLForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            trust_remote_code=True
        ).to(self.device)
        self.model.eval()

        # Qwen2-VL éœ€è¦é¢å¤–çš„åŠ¨ä½œè§£ç å¤´ï¼ˆå‡è®¾å·²å¾®è°ƒï¼‰
        # æˆ–ä½¿ç”¨æç¤ºå·¥ç¨‹ä»Žæ–‡æœ¬ç”ŸæˆåŠ¨ä½œ

    def reset(self):
        """é‡ç½®çŠ¶æ€"""
        if hasattr(self, 'model') and self.model is not None:
            if hasattr(self.model, 'reset'):
                self.model.reset()

    def step(self, obs, goal):
        """
        æŽ¨ç†ä¸€æ­¥

        Args:
            obs: çŽ¯å¢ƒè§‚å¯Ÿ
            goal: è¯­è¨€æŒ‡ä»¤ï¼ˆå­—ç¬¦ä¸²ï¼‰

        Returns:
            action: (7,) numpy array
        """
        rgb_static = obs['rgb_obs']['rgb_static']  # (200, 200, 3)
        rgb_gripper = obs['rgb_obs']['rgb_gripper']  # (84, 84, 3)
        robot_state = obs['robot_obs']  # (15,)

        if self.model_type == "random":
            return self._step_random(rgb_static, rgb_gripper, robot_state, goal)
        elif self.model_type == "openvla":
            return self._step_openvla(rgb_static, rgb_gripper, robot_state, goal)
        elif self.model_type == "rt2":
            return self._step_rt2(rgb_static, rgb_gripper, robot_state, goal)
        elif self.model_type == "octo":
            return self._step_octo(rgb_static, rgb_gripper, robot_state, goal)
        elif self.model_type == "qwen2vl":
            return self._step_qwen2vl(rgb_static, rgb_gripper, robot_state, goal)

    def _step_random(self, rgb_static, rgb_gripper, robot_state, goal):
        """éšæœºåŠ¨ä½œåŸºçº¿"""
        # ç”ŸæˆéšæœºåŠ¨ä½œ
        action = np.zeros(7)

        # xyz ä½ç½®å¢žé‡ (å‰3ç»´)
        action[:3] = np.random.uniform(
            self.action_bounds['xyz'][0],
            self.action_bounds['xyz'][1],
            3
        )

        # rpy æ—‹è½¬å¢žé‡ (ä¸­é—´3ç»´)
        action[3:6] = np.random.uniform(
            self.action_bounds['rpy'][0],
            self.action_bounds['rpy'][1],
            3
        )

        # å¤¹çˆªå¼€åˆ (æœ€åŽ1ç»´)
        action[6] = np.random.choice(self.action_bounds['gripper'])

        return action

    def _step_openvla(self, rgb_static, rgb_gripper, robot_state, goal):
        """OpenVLA æŽ¨ç†"""
        import torch
        from PIL import Image

        # OpenVLA ä½¿ç”¨é™æ€ç›¸æœºå›¾åƒ
        image = Image.fromarray(rgb_static.astype(np.uint8))

        # å‡†å¤‡è¾“å…¥
        prompt = f"In: What action should the robot take to {goal}?\nOut:"
        inputs = self.processor(prompt, image).to(
            self.device,
            dtype=torch.bfloat16
        )

        # æŽ¨ç†
        with torch.no_grad():
            action = self.model.predict_action(**inputs, unnorm_key="bridge_orig")

        return action.cpu().numpy()

    def _step_rt2(self, rgb_static, rgb_gripper, robot_state, goal):
        """RT-2 æŽ¨ç†"""
        import torch
        from PIL import Image

        # RT-2 é€šå¸¸ä½¿ç”¨é™æ€ç›¸æœº
        image = Image.fromarray(rgb_static.astype(np.uint8))

        # å‡†å¤‡è¾“å…¥
        inputs = self.processor(
            text=goal,
            images=image,
            return_tensors="pt"
        ).to(self.device)

        # æŽ¨ç†
        with torch.no_grad():
            outputs = self.model.generate(**inputs)
            # RT-2 è¾“å‡ºéœ€è¦è§£ç ä¸ºåŠ¨ä½œ
            action = self._decode_rt2_action(outputs)

        return action

    def _step_octo(self, rgb_static, rgb_gripper, robot_state, goal):
        """Octo æŽ¨ç†"""
        import jax.numpy as jnp

        # Octo ä½¿ç”¨å¤šè§†è§’å›¾åƒ
        observation = {
            "image_primary": rgb_static,
            "image_wrist": rgb_gripper,
            "proprio": robot_state[:7]  # æœºå™¨äººçŠ¶æ€
        }

        # å‡†å¤‡ä»»åŠ¡
        task = self.model.create_tasks(texts=[goal])

        # æŽ¨ç†
        action = self.model.sample_actions(
            observation,
            task,
            rng=jax.random.PRNGKey(0)
        )

        return np.array(action[0])

    def _step_qwen2vl(self, rgb_static, rgb_gripper, robot_state, goal):
        """Qwen2-VL æŽ¨ç†ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰"""
        import torch
        from PIL import Image

        # Qwen2-VL ä¸»è¦ç”¨äºŽè§†è§‰ç†è§£ï¼Œéœ€è¦å¾®è°ƒæˆ–æç¤ºå·¥ç¨‹
        image = Image.fromarray(rgb_static.astype(np.uint8))

        # æž„å»ºæç¤ºï¼ˆå‡è®¾æ¨¡åž‹å·²å¾®è°ƒè¾“å‡ºåŠ¨ä½œï¼‰
        messages = [
            {
                "role": "system",
                "content": """You are a precise robot arm controller. You MUST output ONLY 7 numbers separated by commas.

        Output format: x,y,z,roll,pitch,yaw,gripper

        Rules:
        - x,y,z: position delta in meters (range: -0.02 to 0.02)
        - roll,pitch,yaw: rotation delta in radians (range: -0.05 to 0.05)  
        - gripper: MUST be exactly 1 (close) or -1 (open), NO other values allowed

        Example output: 0.01,-0.02,0.005,0.0,0.0,0.0,1"""
            },
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": f"Task: {goal}\n\nOutput the next action as 7 numbers:"}
                ],
            }
        ]

        text = self.processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        inputs = self.processor(
            text=[text],
            images=[image],
            return_tensors="pt"
        ).to(self.device)

        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.model.generate(**inputs, max_new_tokens=128)
            response = self.processor.decode(outputs[0], skip_special_tokens=True)

        # ä»Žæ–‡æœ¬è§£æžåŠ¨ä½œ
        action = self._parse_action_from_text(response)
        return action

    def _decode_rt2_action(self, outputs):
        """è§£ç  RT-2 çš„åŠ¨ä½œè¾“å‡º"""
        # RT-2 ä½¿ç”¨ç¦»æ•£åŒ–çš„åŠ¨ä½œç©ºé—´ï¼Œéœ€è¦åé‡åŒ–
        # è¿™é‡Œæ˜¯ç®€åŒ–ç¤ºä¾‹
        decoded = self.processor.decode(outputs[0], skip_special_tokens=True)
        # è§£æžåŠ¨ä½œ token å¹¶è½¬æ¢ä¸ºè¿žç»­åŠ¨ä½œ
        action = np.random.uniform(-0.02, 0.02, 7)  # å ä½å®žçŽ°
        action[-1] = np.random.choice([-1, 1])
        return action

    def _parse_action_from_text(self, text: str):
        """ä»Žæ–‡æœ¬è§£æžåŠ¨ä½œ"""
        try:
            # å°è¯•æå–æ•°å­—
            import re
            numbers = re.findall(r'-?\d+\.?\d*', text)
            if len(numbers) >= 7:
                action = np.array([float(n) for n in numbers[:7]])
                return action
        except:
            pass

        # é»˜è®¤éšæœºåŠ¨ä½œ
        action = np.random.uniform(-0.02, 0.02, 7)
        action[-1] = np.random.choice([-1, 1])
        return action


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ–¹å¼1: ä½¿ç”¨éšæœºåŸºçº¿æ¨¡åž‹ï¼ˆæ— éœ€GPUï¼‰
    print("=" * 50)
    print("æµ‹è¯•éšæœºåŸºçº¿æ¨¡åž‹")
    print("=" * 50)
    model_random = MyVLAModel(model_type="random")

    # æ–¹å¼2: ä½¿ç”¨ OpenVLA
    # model = MyVLAModel(model_type="openvla")

    # æ–¹å¼3: ä½¿ç”¨ RT-2
    # model = MyVLAModel(model_type="rt2")

    # æ–¹å¼4: ä½¿ç”¨ Octo
    # model = MyVLAModel(model_type="octo")

    # æ–¹å¼5: ä½¿ç”¨ Qwen2-VL
    # model = MyVLAModel(model_type="qwen2vl")

    # æ¨¡æ‹Ÿè§‚å¯Ÿ
    obs = {
        'rgb_obs': {
            'rgb_static': np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8),
            'rgb_gripper': np.random.randint(0, 255, (84, 84, 3), dtype=np.uint8)
        },
        'robot_obs': np.random.randn(15)
    }

    goal = "pick up the red block"

    # æµ‹è¯•å¤šä¸ªæ­¥éª¤
    print(f"\nä»»åŠ¡: {goal}\n")
    for i in range(3):
        action = model_random.step(obs, goal)
        print(f"æ­¥éª¤ {i+1} åŠ¨ä½œ: {action}")
        print(f"  - ä½ç½®å¢žé‡ (xyz): {action[:3]}")
        print(f"  - æ—‹è½¬å¢žé‡ (rpy): {action[3:6]}")
        print(f"  - å¤¹çˆª: {'å…³é—­' if action[6] > 0 else 'æ‰“å¼€'}")